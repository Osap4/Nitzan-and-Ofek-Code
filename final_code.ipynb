{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T13:02:51.172022400Z",
     "start_time": "2024-11-27T13:02:51.161274400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "import glob\n",
    "import os\n",
    "from scipy.io import loadmat\n",
    "from filterpy.kalman import KalmanFilter\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Insert paths for parquets and matlab files\n",
    "\n",
    "parquet_path = r'C:\\Users\\OfekSapir\\Desktop\\reptile_lab\\retpile_lab\\perdictions'\n",
    "mat_path = r'C:\\Users\\OfekSapir\\Desktop\\reptile_lab\\retpile_lab\\mat_data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:49:48.949889900Z",
     "start_time": "2024-11-27T12:49:48.946163Z"
    }
   },
   "id": "506ea3a6902c4694",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Filtering by probability and positions based on given parameters\n",
    "def data_prep(parquet, mat, prob_quantile=0.02, pos_std_factor=3):\n",
    "    \n",
    "    # Calculate probability threshold\n",
    "    prob_threshold = parquet[('nose', 'prob')].quantile(prob_quantile)\n",
    "    \n",
    "    # Filter rows with low probability\n",
    "    filtered_parquet = parquet[parquet[('nose', 'prob')] >= prob_threshold].copy()\n",
    "    \n",
    "    # Create positional differences for x and y\n",
    "    filtered_parquet['diff_x'] = filtered_parquet[('nose', 'x')].diff().abs()\n",
    "    filtered_parquet['diff_y'] = filtered_parquet[('nose', 'y')].diff().abs()\n",
    "    \n",
    "    # Calculate mean and std for positional differences\n",
    "    mean_diff_x = np.mean(filtered_parquet['diff_x'].dropna())\n",
    "    std_diff_x = np.std(filtered_parquet['diff_x'].dropna())\n",
    "    \n",
    "    mean_diff_y = np.mean(filtered_parquet['diff_y'].dropna())\n",
    "    std_diff_y = np.std(filtered_parquet['diff_y'].dropna())\n",
    "    \n",
    "    # Calculate positional threshold\n",
    "    x_threshold = mean_diff_x + pos_std_factor * std_diff_x\n",
    "    y_threshold = mean_diff_y + pos_std_factor * std_diff_y\n",
    "    \n",
    "    # Filter rows with high location differences\n",
    "    filtered_parquet = filtered_parquet[\n",
    "        (filtered_parquet['diff_x'] <= x_threshold) &\n",
    "        (filtered_parquet['diff_y'] <= y_threshold)\n",
    "    ]\n",
    "    \n",
    "    # Get relevant columns\n",
    "    raw = filtered_parquet[[('nose', 'x'), ('nose', 'y'), ('time', ''), ('angle', '')]]\n",
    "    raw.columns = raw.columns.map('_'.join)\n",
    "    \n",
    "    # Prepare nose data\n",
    "    nose_x = raw['nose_x'].tolist()\n",
    "    nose_y = raw['nose_y'].tolist()\n",
    "    \n",
    "    # Prepare time delta\n",
    "    time_unix = pd.to_datetime(raw['time_'], unit='s') # Creating Unix time\n",
    "    time_delta = (time_unix - time_unix.min()).dt.total_seconds() # Creating time from zero for plot\n",
    "    \n",
    "    # Determine trial frames from mat\n",
    "    start_frames = list(mat['arenaCSVs']['startFrameSh'])[0][0]\n",
    "    end_frames = list(mat['arenaCSVs']['endFramSh'])[0][0]\n",
    "    \n",
    "    try:\n",
    "        assert len(start_frames) == len(end_frames), \"Mismatch in start and end frame lengths\"\n",
    "    except AssertionError as e:\n",
    "        print(f\"Warning: {e}. Proceeding, but results may be incorrect.\")\n",
    "    \n",
    "    frame_range_lst = []\n",
    "    for i in range(len(start_frames)):\n",
    "        start_value = int(start_frames[i].item()) if isinstance(start_frames[i], (np.ndarray, np.generic)) else int(start_frames[i])\n",
    "        end_value = int(end_frames[i].item()) if isinstance(end_frames[i], (np.ndarray, np.generic)) else int(end_frames[i])\n",
    "        frame_range_lst.append(range(start_value, end_value))\n",
    "    \n",
    "    # Set angle\n",
    "    angle = raw['angle_']\n",
    "    \n",
    "    # Set index\n",
    "    index = list(range(len(raw)))\n",
    "    \n",
    "    # Determine which frames are in the trial \n",
    "    index_max = max(r.stop for r in frame_range_lst)\n",
    "    in_trial = [any(i in r for r in frame_range_lst) for i in range(index_max)]\n",
    "    in_trial.extend([False] * (len(index) - len(in_trial)))\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'frame_num': index, \n",
    "        'time_from_zero': time_delta, \n",
    "        'nose_x': nose_x, \n",
    "        'nose_y': nose_y, \n",
    "        'angle': angle, \n",
    "        'in_trial': in_trial[:len(index)]\n",
    "          })\n",
    "    \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:49:49.161006500Z",
     "start_time": "2024-11-27T12:49:49.156616500Z"
    }
   },
   "id": "5331380bb02a3525",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Screen view probability calculation\n",
    "# Running on data after going through data_prep\n",
    "def screen_view_probability_cal(data):\n",
    "    # Define the target angle (pi/2 radians)\n",
    "    reference_angle_1 = 0\n",
    "    reference_angle_2 = np.pi\n",
    "    \n",
    "    # Calculate the deviation from the target angles\n",
    "    data['angle_deviation'] = np.where(\n",
    "        (reference_angle_1 < data['angle']) & (data['angle'] < reference_angle_2),\n",
    "        0,\n",
    "        np.where(\n",
    "            (3 * np.pi / 2 < data['angle']) & (data['angle'] < 2 * np.pi),\n",
    "            np.abs(2 * np.pi - (data['angle'] - reference_angle_1)),\n",
    "        np.where(\n",
    "            (np.pi < data['angle']) & (data['angle'] < 3 * np.pi / 2),\n",
    "            np.abs(data['angle'] - reference_angle_2),\n",
    "            np.nan  # If the angle does not fall within these ranges\n",
    "        )))\n",
    "    \n",
    "    # Normalize the deviation to create a probability score\n",
    "    threshold = np.pi / 2\n",
    "    data['probability'] = np.clip(1 - (data['angle_deviation'] / threshold), 0, 1)\n",
    "    \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:49:49.358076100Z",
     "start_time": "2024-11-27T12:49:49.353707600Z"
    }
   },
   "id": "2e2f862298eab0ee",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot function nose x-y plane real world\n",
    "def plot_plane(data, date, path_to_save=r'C:\\Users\\OfekSapir\\Desktop\\reptile_lab\\retpile_lab\\filtered', save=False):   \n",
    "    # Assign screen sight probability for each frame\n",
    "    screen_view_probability_cal(data)\n",
    "\n",
    "    # Identify segments where probability is above 0.8\n",
    "    high_prob = data['probability'] > 0.8\n",
    "\n",
    "    default_color = 'black'\n",
    "    highlight_color = 'red'\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data['nose_y'], data['nose_x'], color=default_color, linewidth=2)\n",
    "    \n",
    "    # Plot with highlighting segments based on probability\n",
    "    for i in range(1, len(data)):\n",
    "        color = highlight_color if high_prob.iloc[i] else default_color\n",
    "        plt.plot([data['nose_y'].iloc[i-1], data['nose_y'].iloc[i]], \n",
    "                 [data['nose_x'].iloc[i-1], data['nose_x'].iloc[i]], \n",
    "                 color=color, linewidth=2)\n",
    "\n",
    "    plt.title(f'Nose x-y Plane for {date}')\n",
    "    plt.ylabel('X Coordinates (cm)')\n",
    "    plt.xlabel('Y Coordinates (cm)')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    counter = 1\n",
    "    filename = os.path.join(path_to_save, f'plane_{counter}.png')\n",
    "    while os.path.exists(filename):\n",
    "        counter += 1\n",
    "        filename = os.path.join(path_to_save, f'plane_{counter}.png')\n",
    "\n",
    "    if save:\n",
    "        if not os.path.exists(path_to_save):\n",
    "            os.makedirs(path_to_save)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:49:49.527081300Z",
     "start_time": "2024-11-27T12:49:49.520746200Z"
    }
   },
   "id": "67296288c5a2458e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot function nose x & y coordinates over time\n",
    "def plot_overtime(data, date, path_to_save=r'C:\\Users\\OfekSapir\\Desktop\\reptile_lab\\retpile_lab\\figs', save=False):\n",
    "     # Assign screen sight probability for each frame\n",
    "    screen_view_probability_cal(data)\n",
    "     \n",
    "    coordinates_col = ['nose_x', 'nose_y']\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    for col in coordinates_col:\n",
    "        ax.plot(data['time_from_zero'], data[col], label=f'Coordinate of {col[-1]}')\n",
    "        ax.set_title(f'Location of Pogona Over Time for {date}')\n",
    "        ax.set_xlabel('Timestamp')\n",
    "        ax.set_ylabel('Coordinates (cm)')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    counter = 1\n",
    "    filename = os.path.join(path_to_save, f'overtime_plane_{counter}.png')\n",
    "    while os.path.exists(filename):\n",
    "        counter += 1\n",
    "        filename = os.path.join(path_to_save, f'overtime_plane_{counter}.png')\n",
    "        \n",
    "    if save:\n",
    "        if not os.path.exists(path_to_save):\n",
    "            os.makedirs(path_to_save)\n",
    "        plt.savefig(filename)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:48:51.856309700Z",
     "start_time": "2024-11-27T12:48:51.843607400Z"
    }
   },
   "id": "f60a83113ff04f17",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# First self written Kalman filter\n",
    "# Example for parameters is given below\n",
    "def kalman_filter_1(data, process_variance, measurement_variance, estimated_error, initial_value):\n",
    "    n = len(data)\n",
    "    kalman_estimates = np.zeros(n)\n",
    "    kalman_gain = 0\n",
    "\n",
    "    # Initial guesses\n",
    "    current_estimate = initial_value\n",
    "    current_error = estimated_error\n",
    "\n",
    "    for i in range(n):\n",
    "        # Kalman Gain\n",
    "        kalman_gain = current_error / (current_error + measurement_variance)\n",
    "        \n",
    "        # Update estimate with measurement\n",
    "        current_estimate = current_estimate + kalman_gain * (data[i] - current_estimate)\n",
    "        kalman_estimates[i] = current_estimate\n",
    "        \n",
    "        # Update the error covariance\n",
    "        current_error = (1 - kalman_gain) * current_error + process_variance\n",
    "    \n",
    "    return kalman_estimates\n",
    "process_variance = 1e-4  # Small value for smoother results (adjust as needed)\n",
    "measurement_variance = 0.001  # Measurement noise (adjust based on your data)\n",
    "estimated_error = 0.1 # Initial estimate error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T12:52:49.624453600Z",
     "start_time": "2024-11-27T12:52:49.618413800Z"
    }
   },
   "id": "d723e642ed4ab9c8",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Second Kalman filter created by the package KalmanFilter\n",
    "# Output is a body part coordinates\n",
    "def kalman_filter_2(coords):\n",
    "    kf = KalmanFilter(dim_x=2, dim_z=1)  # 2 states (position, velocity), 1 measurement\n",
    "    \n",
    "    # Initial state: assume starting at first coordinate with zero initial velocity\n",
    "    kf.x = np.array([[coords[0]], [0]])  \n",
    "    \n",
    "    # State transition matrix (F)\n",
    "    dt = 1  # Assuming 1 frame step; adjust if time interval is different\n",
    "    kf.F = np.array([[1, dt], [0, 1]])\n",
    "    \n",
    "    # Measurement function (H): we only measure position\n",
    "    kf.H = np.array([[1, 0]])\n",
    "    \n",
    "    # Measurement noise covariance (R): based on data variance\n",
    "    kf.R = np.array([[np.var(coords) * 0.01]])  # Scaled down to smooth more aggressively\n",
    "    \n",
    "    # Process noise covariance (Q)\n",
    "    kf.Q = np.array([[1e-4, 0], [0, 1e-4]])  # Small values to maintain smoothness\n",
    "    \n",
    "    # Initial state covariance (P)\n",
    "    kf.P = np.eye(2) * 500\n",
    "    \n",
    "    # Apply the filter\n",
    "    smoothed_coords = []\n",
    "    for z in coords:\n",
    "        kf.predict()\n",
    "        kf.update([[z]])\n",
    "        smoothed_coords.append(kf.x[0, 0])  # Extract filtered position\n",
    "    \n",
    "    return np.array(smoothed_coords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T13:03:17.284698600Z",
     "start_time": "2024-11-27T13:03:17.274525300Z"
    }
   },
   "id": "88e1b92beaa47423",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Mismatch in start and end frame lengths. Proceeding, but results may be incorrect.\n"
     ]
    }
   ],
   "source": [
    "# Setting up the data\n",
    "parquet_files = glob.glob(os.path.join(parquet_path, '**', '*.parquet'), recursive=True)\n",
    "mat_files = glob.glob(os.path.join(mat_path, '**', '*.mat'), recursive=True)\n",
    "\n",
    "parquet_dict = {}\n",
    "mat_lst = []\n",
    "data_lst = []\n",
    "data_lst_with_prob = []\n",
    "\n",
    "# Load the parquets data\n",
    "for i, file in enumerate(parquet_files):\n",
    "    date = str(file[-17:-15] + '/' + file[-19:-17] + '/' + file[-23:-19])\n",
    "    parquet_dict[date] = pd.read_parquet(file, engine='pyarrow')\n",
    "\n",
    "# Load the matlab tables data \n",
    "for j, mat in enumerate(mat_files):\n",
    "    mat_lst.append(loadmat(mat))\n",
    "\n",
    "# Preparing the data for work\n",
    "for parquet_val, mat in zip(parquet_dict.values(), mat_lst):\n",
    "    data_lst.append(data_prep(parquet_val, mat, pos_std_factor=0))\n",
    "\n",
    "# Calculating screen view probabilities for the data\n",
    "for data in data_lst:\n",
    "    prob_data = screen_view_probability_cal(data)\n",
    "    data_lst_with_prob.append(prob_data)\n",
    "    \n",
    "if len(parquet_dict.keys()) != len(mat_lst):\n",
    "    print('Parquet files and mat files are not synced!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-27T13:07:01.749864400Z",
     "start_time": "2024-11-27T13:07:00.163041Z"
    }
   },
   "id": "4d835b4d58716773",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting positional distribution box-whisker plot / violin plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "labels = list(parquet_dict.keys())\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']\n",
    "\n",
    "# values = [np.log1p(value['diff_x']) for value in parquet_dict.values()]\n",
    "values = [value['diff_x'] for value in parquet_dict.values()]\n",
    "\n",
    "# values_df = pd.concat(values, axis=1)\n",
    "# values_df.columns = [labels[0], labels[1], labels[2], labels[3], labels[4], labels[5]]\n",
    "# melted_values = values_df.melt(var_name='label', value_name='value')\n",
    "\n",
    "for value in values:\n",
    "    if pd.isna(value.iloc[0]):  \n",
    "        value.iloc[0] = 0\n",
    "        \n",
    "\n",
    "\n",
    "# sns.violinplot(x='label', y='value', data=melted_values)\n",
    "ax.boxplot(values, tick_labels=labels)\n",
    "ax.set_xticks(range(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.set_ylabel('Amount')\n",
    "ax.set_title('Position Difference Distribution')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fb62230c6b0599a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting positional difference distribution histogram\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "above_10 = []\n",
    "for label, value, color in zip(labels, parquet_dict.values(), colors):\n",
    "    value['diff_x'] = value[('nose', 'x')].diff().abs()\n",
    "    mean_diff_x = np.mean(value['diff_x'].dropna())\n",
    "    std_diff_x = np.std(value['diff_x'].dropna())\n",
    "    above_10.append((value['diff_x'] >= mean_diff_x + std_diff_x * 10).sum())\n",
    "    tenth_threshold = mean_diff_x + std_diff_x * 10\n",
    "    \n",
    "    ax.hist(value['diff_x'], bins=200, alpha=0.7)\n",
    "    plt.xlim(0.95,50)\n",
    "    plt.ylim(0,20)\n",
    "    ax.axvline(mean_diff_x, color='green', linestyle='dashed', linewidth=1, label=f'Mean: {mean_diff_x:.2f}')\n",
    "    ax.axvline(\n",
    "    tenth_threshold, color=color, linestyle='dashed', linewidth=1,\n",
    "    label=f'10 STDs Threshold: {tenth_threshold:.2f} for {label}'\n",
    "    )\n",
    "\n",
    "text = f\"Number of frames above 10 STDs\\n{above_10[0]} for {labels[0]}\\n{above_10[1]} for {labels[1]}\\n{above_10[2]} for {labels[2]}\\n{above_10[3]} for {labels[3]}\\n{above_10[4]} for {labels[4]}\\n{above_10[5]} for {labels[5]}\"\n",
    "plt.text(\n",
    "    0.95, 0.95, \n",
    "    text,\n",
    "    fontsize=12,\n",
    "    color=\"white\",\n",
    "    ha=\"right\",  \n",
    "    va=\"top\",     \n",
    "    transform=ax.transAxes,  \n",
    "    bbox=dict(facecolor=\"darkolivegreen\", edgecolor=\"none\", boxstyle=\"round,pad=0.5\")\n",
    ")\n",
    "plt.xlabel('Difference Between Coordinates')\n",
    "plt.ylabel('Amount')\n",
    "plt.legend()\n",
    "plt.title('Position Difference Distribution')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deaa29bfa257daf0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting probabilities distribution box-whisker plot\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "data = [v[('nose', 'prob')] for v in parquet_dict.values()]\n",
    "labels = list(parquet_dict.keys())\n",
    "\n",
    "ax.boxplot(data, tick_labels=labels)\n",
    "ax.axhline(y=0.8, color='black', linestyle='--', linewidth=1.5, label=\"Threshold = 0.8\")\n",
    "ax.set_xticks(range(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_title(\"Distribution of Predictions Probabilities for 6 Experiments\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9b2703a20ee9c76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting nose x-y plane real world\n",
    "for v in range(len(mat_lst)):\n",
    "    data = data_prep(list(parquet_dict.values())[v],mat_lst[v], pos_std_factor=10)\n",
    "    \n",
    "    data_for_kalman = data_prep(list(parquet_dict.values())[v],mat_lst[v], pos_std_factor=0)\n",
    "    \n",
    "    kf1_data = data_for_kalman.copy()\n",
    "    nose_x_kf1 = np.array(kf1_data['nose_x'])\n",
    "    nose_y_kf1 = np.array(kf1_data['nose_y'])\n",
    "    # kalman_filter_1 parameters\n",
    "    process_variance = 1e-4  \n",
    "    measurement_variance = 0.001 \n",
    "    estimated_error = 0.1  \n",
    "    initial_value_x = nose_x_kf1[0]\n",
    "    initial_value_y = nose_y_kf1[0]\n",
    "    kf1_data['nose_x'] = kalman_filter_1(nose_x_kf1, process_variance, measurement_variance, estimated_error, initial_value_x)\n",
    "    kf1_data['nose_y'] = kalman_filter_1(nose_y_kf1, process_variance, measurement_variance, estimated_error, initial_value_y)\n",
    "    \n",
    "    kf2_data = data_for_kalman.copy()\n",
    "    kf2_data['nose_x'] = kalman_filter_2(kf2_data['nose_x'].values)\n",
    "    kf2_data['nose_y'] = kalman_filter_2(kf2_data['nose_y'].values)\n",
    "    \n",
    "    plot_plane(data, f'{list(parquet_dict.keys())[v]}, std factor = 10', save=True)\n",
    "    plot_plane(kf1_data, f'{list(parquet_dict.keys())[v]}, kalman filter 1', save=True)\n",
    "    plot_plane(kf2_data, f'{list(parquet_dict.keys())[v]}, kalman filter 2', save=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b71e2e2d0f8f391"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
